{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import xmltodict\n",
    "import sqlite3\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "conn = sqlite3.connect(\"human_protein.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.path.exists('data\\\\reviewed_human_protein.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a couple minutes\n",
    "with open('data/reviewed_human_protein.xml') as f:\n",
    "    human_protein_dict = xmltodict.parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['uniprot'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_protein_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['@xmlns', '@xmlns:xsi', '@xsi:schemaLocation', 'entry', 'copyright'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_protein_dict['uniprot'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['@dataset', '@created', '@modified', '@version', 'accession', 'name', 'protein', 'gene', 'organism', 'reference', 'comment', 'dbReference', 'proteinExistence', 'keyword', 'feature', 'evidence', 'sequence'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry = human_protein_dict['uniprot']['entry'][0]\n",
    "entry.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human_protein_dict['uniprot']['entry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def commentAlgo(comment,locs,):\n",
    "    \"\"\"I'm having a problem with entries sometimes being lists or flat entries\"\"\"\n",
    "\n",
    "def entryCommentParser(entry_name, comments):\n",
    "    function_list = []\n",
    "    disease_list = []\n",
    "    tissue_list = []\n",
    "    subcellular_list = []\n",
    "    if type(comments)!=list:\n",
    "        comments = [comments]\n",
    "    for comment in comments:\n",
    "        comm_arr = [entry_name]\n",
    "        comm_type = comment.get(\"@type\",None)\n",
    "        value = comment.get(\"text\")\n",
    "        if comm_type in ['function','pathway','activity regulation','similarity']:\n",
    "            if value!=None and type(value)!=str:\n",
    "                value = value.get(\"#text\")\n",
    "                comm_arr.extend([comm_type, value])\n",
    "                function_list.append(comm_arr)\n",
    "        elif comm_type=='disease':\n",
    "            comm_disease = comment.get('disease')\n",
    "            if type(comm_disease)!='str' and comm_disease!=None:\n",
    "                comm_arr.append(comment.get('disease').get(\"name\"))\n",
    "                disease_list.append(comm_arr)\n",
    "        elif comm_type=='tissue specificity':\n",
    "            value = comment.get('text')\n",
    "            if type(value)!=str:\n",
    "                value = value.get(\"#text\")\n",
    "            comm_arr.append(value)\n",
    "            tissue_list.append(comm_arr)\n",
    "        # This is a really messily annotated section in these entries...sheesh!\n",
    "        elif comm_type=='subcellular location':\n",
    "            locs = []\n",
    "            loc_source = comment.get('subcellularLocation')\n",
    "            if type(loc_source)!=list:\n",
    "                loc_source = [loc_source]\n",
    "            for loc_head in loc_source:\n",
    "                if loc_head == None:\n",
    "                    pass\n",
    "                else:\n",
    "                    sub_locs = loc_head.get('location')\n",
    "                    if type(sub_locs)==list:\n",
    "                        for sub_sub_locs in sub_locs:\n",
    "                            if type(sub_sub_locs)==str:\n",
    "                                value = sub_sub_locs\n",
    "                            else:\n",
    "                                value = sub_sub_locs.get('#text')\n",
    "                            if value not in locs:\n",
    "                                locs.append(value)\n",
    "                                subcellular_list.append([entry_name, value])\n",
    "                    elif type(sub_locs)==str:\n",
    "                        value = sub_locs\n",
    "                    else:\n",
    "                        value = sub_locs.get('#text')\n",
    "                    if value not in locs:\n",
    "                        locs.append(value)\n",
    "                        subcellular_list.append([entry_name, value])\n",
    "        else:\n",
    "            pass\n",
    "    return function_list, disease_list, tissue_list, subcellular_list\n",
    "\n",
    "def featureParser(entry_name, features):\n",
    "    \"\"\"Right now I only want features that are annotations of;\n",
    "    \n",
    "    -strand (beta sheet)\n",
    "    -helix  (alpha helix)\n",
    "    -turn   (highly structured secondary structure)\n",
    "    \n",
    "    \"\"\"\n",
    "    sec_struc_list = []\n",
    "    modified_residues = []\n",
    "    feat_arr = []\n",
    "    for feature in features:\n",
    "        if type(feature)==str:\n",
    "            pass\n",
    "        else:\n",
    "            feat_type = feature.get(\"@type\")\n",
    "            if feat_type in ['strand','helix','turn']:\n",
    "                feat_locations = feature.get('location')\n",
    "                feat_begin = feat_locations.get('begin').get('@position')\n",
    "                feat_end = feat_locations.get('end').get('@position')\n",
    "                sec_struc_list.append([entry_name, feat_type, feat_begin, feat_end])\n",
    "            elif feat_type in ['modified residue','non-standard residue','lipidation',\n",
    "                               'glycosylation','disulfide bond','cross-link']:\n",
    "                feat_desc = feature.get(\"@description\")\n",
    "                feat_posi = feature.get(\"location\")\n",
    "                if 'begin' in feat_posi.keys():\n",
    "                    begin = feat_posi.get('begin').get(\"@position\")\n",
    "                    end = feat_posi.get('end').get(\"@position\")\n",
    "                    if begin==None:\n",
    "                        feat_posi = end\n",
    "                    elif end==None:\n",
    "                        feat_posi = begin\n",
    "                    elif begin==None and end==None:\n",
    "                        feat_posi = None\n",
    "                    else:\n",
    "                        feat_posi = begin+\"-\"+end\n",
    "                else:\n",
    "                    feat_posi = feat_posi.get('position').get(\"@position\")\n",
    "                modified_residues.append([entry_name, feat_type, feat_desc, feat_posi])\n",
    "\n",
    "    return sec_struc_list, modified_residues\n",
    "\n",
    "def keywordParser(keyword):\n",
    "    text = []\n",
    "    for x in keyword:\n",
    "        if type(x)==str:\n",
    "            text.append(x)\n",
    "        elif x!=None and type(x)!=str:\n",
    "            text.append(x.get('#text'))\n",
    "    return ', '.join(text)\n",
    "\n",
    "def entryParser(entry, conn, print_option=False):\n",
    "    # Get name\n",
    "    entry_name = entry.get('name')\n",
    "    # Get sequence\n",
    "    entry_seq = entry.get('sequence').get('#text').replace(\"\\n\",\"\").strip()\n",
    "    # Parse keywords\n",
    "    entry_keywords = \"\"\n",
    "    if entry.get('keyword')!=None:\n",
    "        entry_keywords = keywordParser(entry.get('keyword'))\n",
    "    # Parse features\n",
    "    entry_features = entry.get('feature')\n",
    "    sec_struc_list, modified_residues = featureParser(entry_name, entry_features)\n",
    "    # Parse comments\n",
    "    entry_comments = entry.get('comment', None)\n",
    "    comm_list = []\n",
    "    disease_list = []\n",
    "    tissue_list = []\n",
    "    subcellular_list = []\n",
    "    if entry_comments != None:\n",
    "        comm_list, disease_list, tissue_list, subcellular_list \\\n",
    "        = entryCommentParser(entry_name, entry_comments)\n",
    "    \n",
    "    # One row each protein: protein name, sequence and keyword string\n",
    "    protein_df = pd.DataFrame([[entry_name, entry_seq, entry_keywords]],\n",
    "                              columns=[\"protein\",\"sequence\",\"keywords\"])\n",
    "    # Multiple rows each protein for secondary structure: protein name, secondary structure type,\n",
    "    # where it starts, where it ends\n",
    "    sec_struc_df = pd.DataFrame(sec_struc_list,\n",
    "                                columns=[\"protein\",\"sec_struc_type\",\"begin\",\"end\"])\n",
    "    # Multiple rows each protein: protein name, modification type, description of modification,\n",
    "    # position of modification\n",
    "    aa_mod_df = pd.DataFrame(modified_residues,\n",
    "                             columns=['protein','modification','description','position'])\n",
    "    # Multiple rows each protein for comments: protein name, comment type, comment value\n",
    "    comment_df = pd.DataFrame(comm_list, columns=[\"protein\",\"comm_type\",\"value\"])\n",
    "    \n",
    "    # Multiple rows each protein for disease associations: protein name, disease name\n",
    "    disease_df = pd.DataFrame(disease_list, columns=[\"protein\",\"disease\"])\n",
    "    \n",
    "    # Multiple rows each protein for tissue expression: protein name, tissue\n",
    "    tissue_df = pd.DataFrame(tissue_list, columns=['protein','disease'])\n",
    "    \n",
    "    # Multiple rows each protein for subcellular localization: protein name, subcellular loc\n",
    "    subcellular_df = pd.DataFrame(subcellular_list, columns=['protein','subcellular_loc'])\n",
    "    \n",
    "    if print_option:\n",
    "        if protein_df.shape[0]!=0:\n",
    "            print(\"Protein DataFrame\")\n",
    "            display(protein_df)\n",
    "        if sec_struc_df.shape[0]!=0:\n",
    "            print(\"Secondary structure DataFrame\")\n",
    "            display(sec_struc_df)\n",
    "        if aa_mod_df.shape[0]!=0:\n",
    "            print(\"Amino Acid Modifications\")\n",
    "            display(aa_mod_df)\n",
    "        if comment_df.shape[0]!=0:\n",
    "            print(\"Comment DataFrame\")\n",
    "            display(comment_df)\n",
    "        if disease_df.shape[0]!=0:\n",
    "            print(\"Disease DataFrame\")\n",
    "            display(disease_df)\n",
    "        if tissue_df.shape[0]!=0:\n",
    "            print(\"Tissue DataFrame\")\n",
    "            display(tissue_df)\n",
    "        if subcellular_df.shape[0]!=0:\n",
    "            print(\"Subcellular Location DataFrame\")\n",
    "            display(subcellular_df)\n",
    "            \n",
    "    # Record entries in sqlite\n",
    "    if protein_df.shape[0]!=0:\n",
    "        protein_df.to_sql('protein',conn,if_exists='append',index=False)\n",
    "    if sec_struc_df.shape[0]!=0:\n",
    "        sec_struc_df.to_sql('protein_secondary_structure',conn,if_exists='append',index=False)\n",
    "    if aa_mod_df.shape[0]!=0:\n",
    "        aa_mod_df.to_sql('protein_amino_acid_modifications',conn,if_exists='append',index=False)\n",
    "    if comment_df.shape[0]!=0:\n",
    "        comment_df.to_sql('protein_comments',conn,if_exists='append',index=False)\n",
    "    if disease_df.shape[0]!=0:\n",
    "        disease_df.to_sql('protein_diseases',conn,if_exists='append',index=False)\n",
    "    if tissue_df.shape[0]!=0:\n",
    "        tissue_df.to_sql('protein_tissue_expression',conn,if_exists='append',index=False)\n",
    "    if subcellular_df.shape[0]!=0:\n",
    "        subcellular_df.to_sql('protein_subcellular_localization',conn,if_exists='append',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab16974f8f634965962f771aaf19e77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20394), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Takes a little over 15 minutes\n",
    "for entry in tqdm_notebook(human_protein_dict['uniprot']['entry']):\n",
    "    entryParser(entry,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
